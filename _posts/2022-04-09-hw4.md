---
layout: post
title: Homework 4
---
In this blog, I will develop and assess a fake news classifer using Tensorflow.

# 1. Acquire Training Data
```python
import pandas as pd
import numpy as np
train_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true"
df = pd.read_csv(train_url)
```
Using  `df.head()` check the data that get from train_url.
```
df.head()
```
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>title</th>
      <th>text</th>
      <th>fake</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>17366</td>
      <td>Merkel: Strong result for Austria's FPO 'big c...</td>
      <td>German Chancellor Angela Merkel said on Monday...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5634</td>
      <td>Trump says Pence will lead voter fraud panel</td>
      <td>WEST PALM BEACH, Fla.President Donald Trump sa...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>17487</td>
      <td>JUST IN: SUSPECTED LEAKER and Close Confidant...</td>
      <td>On December 5, 2017, Circa s Sara Carter warne...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>12217</td>
      <td>Thyssenkrupp has offered help to Argentina ove...</td>
      <td>Germany s Thyssenkrupp, has offered assistance...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5535</td>
      <td>Trump say appeals court decision on travel ban...</td>
      <td>President Donald Trump on Thursday called the ...</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

# §2. Make a Dataset
Write a function `make_dataset`. First,And remove stopwords from the text and title. Then, using construct and use `tf.data.Dataset` with multiple inputs. Finally, batch hte dataset and return the dataset.
```python
import tensorflow as tf
from nltk.corpus import stopwords
stop = stopwords.words('english')
def make_dataset(df):
    df["title"] = df["title"].apply(lambda x: " ".join([word for word in x.split() if word not in (stop)]))
    df["text"] = df["text"].apply(lambda x: " ".join([word for word in x.split() if word not in (stop)]))
    dataset = tf.data.Dataset.from_tensor_slices(
        (
            {
                "title":df[["title"]],
                "text":df[["text"]]
            },
            {
                "fake":df[["fake"]]
            }     
        )
    )
    data = dataset.shuffle(buffer_size = len(dataset))
    data = data.batch(100)
    return data
dataset = make_dataset(df)
```